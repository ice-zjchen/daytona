# Daytona æœ¬åœ°éƒ¨ç½²ä¸ Python SDK è°ƒåº¦ Docker å®Œæ•´æ•™ç¨‹

## ç›®å½•
1. [Daytona ç®€ä»‹](#1-daytona-ç®€ä»‹)
2. [ç¯å¢ƒå‡†å¤‡](#2-ç¯å¢ƒå‡†å¤‡)
3. [Daytona æœ¬åœ°éƒ¨ç½²](#3-daytona-æœ¬åœ°éƒ¨ç½²)
4. [Python SDK ä½¿ç”¨](#4-python-sdk-ä½¿ç”¨)
5. [Docker è°ƒåº¦å®è·µ](#5-docker-è°ƒåº¦å®è·µ)
6. [é«˜çº§ç”¨æ³•ä¸æœ€ä½³å®è·µ](#6-é«˜çº§ç”¨æ³•ä¸æœ€ä½³å®è·µ)
7. [å¸¸è§é—®é¢˜è§£å†³](#7-å¸¸è§é—®é¢˜è§£å†³)

## 1. Daytona ç®€ä»‹

Daytona æ˜¯ä¸€ä¸ªå¼€æºçš„å¼€å‘ç¯å¢ƒç®¡ç†å·¥å…·ï¼Œä¸»è¦ç‰¹ç‚¹ï¼š

- **å®¹å™¨åŒ–ç¯å¢ƒ**ï¼šé€šè¿‡ Docker å®¹å™¨åˆ›å»ºéš”ç¦»çš„å¼€å‘ç¯å¢ƒ
- **é…ç½®æ–‡ä»¶é©±åŠ¨**ï¼šä½¿ç”¨ `devcontainer.json` å®šä¹‰ç¯å¢ƒé…ç½®
- **ä¸€è‡´æ€§ä¿è¯**ï¼šç¡®ä¿å›¢é˜Ÿæˆå‘˜ä½¿ç”¨ç›¸åŒçš„å¼€å‘ç¯å¢ƒ
- **å¿«é€Ÿå¯åŠ¨**ï¼šä¸€æ¡å‘½ä»¤åˆ›å»ºå®Œæ•´çš„å¼€å‘ç¯å¢ƒ
- **å¤šå¹³å°æ”¯æŒ**ï¼šæ”¯æŒ Linuxã€macOS å’Œ Windows

### æ ¸å¿ƒä¼˜åŠ¿
- è§£å†³"åœ¨æˆ‘æœºå™¨ä¸Šèƒ½è·‘"çš„é—®é¢˜
- æ”¯æŒ GPU åŠ é€Ÿï¼Œé€‚åˆ AI/ML é¡¹ç›®
- ä¸ä¸»æµ IDE æ— ç¼é›†æˆ
- æ”¯æŒè¿œç¨‹å¼€å‘

## 2. ç¯å¢ƒå‡†å¤‡

### 2.1 ç³»ç»Ÿè¦æ±‚
- **æ“ä½œç³»ç»Ÿ**ï¼šLinux (æ¨è Ubuntu 20.04+)ã€macOSã€Windows 10/11
- **å†…å­˜**ï¼šè‡³å°‘ 8GB RAM
- **å­˜å‚¨**ï¼šè‡³å°‘ 20GB å¯ç”¨ç©ºé—´
- **ç½‘ç»œ**ï¼šç¨³å®šçš„äº’è”ç½‘è¿æ¥

### 2.2 å¿…éœ€è½¯ä»¶

#### å®‰è£… Docker
```bash
# Ubuntu/Debian
sudo apt update
sudo apt install -y docker.io docker-compose
sudo systemctl start docker
sudo systemctl enable docker
sudo usermod -aG docker $USER

# éªŒè¯å®‰è£…
docker --version
docker-compose --version
```

#### å®‰è£… Docker (å…¶ä»–ç³»ç»Ÿ)
```bash
# macOS (ä½¿ç”¨ Homebrew)
brew install --cask docker

# Windows
# ä¸‹è½½å¹¶å®‰è£… Docker Desktop
# https://www.docker.com/products/docker-desktop
```

### 2.3 Python ç¯å¢ƒ
```bash
# ç¡®ä¿ Python 3.8+ å·²å®‰è£…
python3 --version

# å®‰è£… pip
sudo apt install python3-pip

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv daytona-env
source daytona-env/bin/activate  # Linux/macOS
# æˆ– Windows: daytona-env\Scripts\activate
```

## 3. Daytona æœ¬åœ°éƒ¨ç½²

### 3.1 å®‰è£… Daytona

#### æ–¹æ³• 1ï¼šç›´æ¥å®‰è£…ï¼ˆæ¨èï¼‰
```bash
# Linux/macOS
curl -fsSL https://download.daytona.io/daytona/install.sh | bash

# Windows (PowerShell)
Invoke-WebRequest -Uri "https://download.daytona.io/daytona/latest/daytona-windows-amd64.exe" -OutFile "daytona.exe"
# å°† daytona.exe æ·»åŠ åˆ° PATH ç¯å¢ƒå˜é‡
```

#### æ–¹æ³• 2ï¼šä»æºç æ„å»º
```bash
# å…‹éš†ä»“åº“
git clone https://github.com/daytonaio/daytona.git
cd daytona

# æ„å»º
make build

# å®‰è£…
sudo mv bin/daytona /usr/local/bin/
```

### 3.2 å¯åŠ¨ Daytona æœåŠ¡å™¨

```bash
# å¯åŠ¨ Daytona æœåŠ¡å™¨
daytona server

# æœåŠ¡å™¨é»˜è®¤è¿è¡Œåœ¨ http://localhost:3000
```

### 3.3 é…ç½® Git æä¾›å•†

```bash
# æ·»åŠ  GitHub æä¾›å•†
daytona git-provider add

# é€‰æ‹© GitHub å¹¶æä¾› Personal Access Token
# Token éœ€è¦ä»¥ä¸‹æƒé™ï¼š
# - repo (ä»“åº“è®¿é—®)
# - workflow (GitHub Actions)
# - read:user (ç”¨æˆ·ä¿¡æ¯)
```

### 3.4 é€‰æ‹© IDE

```bash
# é…ç½®é»˜è®¤ IDE
daytona ide

# æ”¯æŒçš„ IDEï¼š
# - VS Code
# - JetBrains ç³»åˆ—
# - Vim/Neovim
# - æµè§ˆå™¨å†… IDE
```

## 4. Python SDK ä½¿ç”¨

### 4.1 å®‰è£… Python SDK

```bash
# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source daytona-env/bin/activate

# å®‰è£… Daytona SDK
pip install daytona-sdk

# éªŒè¯å®‰è£…
python -c "import daytona_sdk; print('Daytona SDK å®‰è£…æˆåŠŸ')"
```

### 4.2 åŸºç¡€é…ç½®

```python
# config.py
from daytona_sdk import Daytona, DaytonaConfig

# é…ç½® Daytona å®¢æˆ·ç«¯
config = DaytonaConfig(
    api_url="http://localhost:3000",  # Daytona æœåŠ¡å™¨åœ°å€
    api_key="your-api-key-here"       # ä» Daytona Dashboard è·å–
)

client = Daytona(config)
```

### 4.3 è·å– API Key

```bash
# åœ¨ Daytona Dashboard ä¸­è·å– API Key
# è®¿é—®ï¼šhttp://localhost:3000/dashboard/keys
# æˆ–ä½¿ç”¨å‘½ä»¤è¡Œ
daytona api-key generate
```

### 4.4 åŸºæœ¬ SDK ä½¿ç”¨ç¤ºä¾‹

```python
# basic_usage.py
from daytona_sdk import Daytona, DaytonaConfig, CreateSandboxParams
import time

class DaytonaManager:
    def __init__(self, api_key):
        self.config = DaytonaConfig(
            api_url="http://localhost:3000",
            api_key=api_key
        )
        self.client = Daytona(self.config)
    
    def create_sandbox(self, language="python", image=None):
        """åˆ›å»ºæ–°çš„æ²™ç›’ç¯å¢ƒ"""
        try:
            params = CreateSandboxParams(
                language=language,
                image=image or "python:3.9"
            )
            
            sandbox = self.client.create(params)
            print(f"âœ… æ²™ç›’åˆ›å»ºæˆåŠŸ: {sandbox.id}")
            return sandbox
            
        except Exception as e:
            print(f"âŒ æ²™ç›’åˆ›å»ºå¤±è´¥: {e}")
            return None
    
    def list_sandboxes(self):
        """åˆ—å‡ºæ‰€æœ‰æ²™ç›’"""
        try:
            sandboxes = self.client.list()
            print(f"ğŸ“¦ å½“å‰æ²™ç›’æ•°é‡: {len(sandboxes)}")
            for sandbox in sandboxes:
                print(f"  - {sandbox.id}: {sandbox.status}")
            return sandboxes
        except Exception as e:
            print(f"âŒ è·å–æ²™ç›’åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    def execute_code(self, sandbox, code):
        """åœ¨æ²™ç›’ä¸­æ‰§è¡Œä»£ç """
        try:
            response = sandbox.process.code_run(code)
            if response.exit_code == 0:
                print(f"âœ… ä»£ç æ‰§è¡ŒæˆåŠŸ:")
                print(f"ğŸ“ è¾“å‡º: {response.result}")
            else:
                print(f"âŒ ä»£ç æ‰§è¡Œå¤±è´¥:")
                print(f"ğŸš¨ é”™è¯¯: {response.result}")
            return response
        except Exception as e:
            print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
            return None
    
    def cleanup_sandbox(self, sandbox):
        """æ¸…ç†æ²™ç›’"""
        try:
            self.client.remove(sandbox)
            print(f"ğŸ—‘ï¸ æ²™ç›’å·²æ¸…ç†: {sandbox.id}")
        except Exception as e:
            print(f"âŒ æ¸…ç†å¤±è´¥: {e}")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # æ›¿æ¢ä¸ºä½ çš„ API Key
    API_KEY = "your-api-key-here"
    
    manager = DaytonaManager(API_KEY)
    
    # åˆ›å»ºæ²™ç›’
    sandbox = manager.create_sandbox()
    
    if sandbox:
        # æ‰§è¡Œç®€å•çš„ Python ä»£ç 
        test_code = """
print("Hello from Daytona Sandbox!")
import sys
print(f"Python ç‰ˆæœ¬: {sys.version}")

# ç®€å•è®¡ç®—
result = 2 + 2
print(f"2 + 2 = {result}")
"""
        
        manager.execute_code(sandbox, test_code)
        
        # åˆ—å‡ºæ‰€æœ‰æ²™ç›’
        manager.list_sandboxes()
        
        # æ¸…ç†
        time.sleep(2)
        manager.cleanup_sandbox(sandbox)
```

## 5. Docker è°ƒåº¦å®è·µ

### 5.1 åˆ›å»º Dev Container é…ç½®

```json
// .devcontainer/devcontainer.json
{
    "name": "Python ML Environment",
    "image": "mcr.microsoft.com/devcontainers/python:3.11-bullseye",
    
    "features": {
        "ghcr.io/devcontainers/features/docker-in-docker:2": {},
        "ghcr.io/devcontainers/features/nvidia-cuda:1": {
            "installCudnn": true
        }
    },
    
    "customizations": {
        "vscode": {
            "settings": {
                "python.defaultInterpreterPath": "/usr/local/bin/python",
                "python.linting.enabled": true,
                "python.linting.pylintEnabled": true
            },
            "extensions": [
                "ms-python.python",
                "ms-python.vscode-pylance",
                "ms-toolsai.jupyter"
            ]
        }
    },
    
    "postCreateCommand": "pip install -r requirements.txt",
    "remoteUser": "vscode",
    
    "forwardPorts": [8888, 6006],
    "portsAttributes": {
        "8888": {
            "label": "Jupyter Lab",
            "onAutoForward": "notify"
        },
        "6006": {
            "label": "TensorBoard",
            "onAutoForward": "notify"
        }
    },
    
    "mounts": [
        "source=${localWorkspaceFolder}/data,target=/workspace/data,type=bind"
    ]
}
```

### 5.2 é«˜çº§ Docker è°ƒåº¦ç¤ºä¾‹

```python
# docker_scheduler.py
from daytona_sdk import Daytona, DaytonaConfig, CreateSandboxParams
import json
import time

class DockerScheduler:
    def __init__(self, api_key):
        self.config = DaytonaConfig(
            api_url="http://localhost:3000",
            api_key=api_key
        )
        self.client = Daytona(self.config)
        self.active_containers = {}
    
    def create_ml_environment(self):
        """åˆ›å»ºæœºå™¨å­¦ä¹ ç¯å¢ƒ"""
        devcontainer_config = {
            "name": "ML Sandbox",
            "image": "tensorflow/tensorflow:2.15.0-gpu-jupyter",
            "features": {
                "ghcr.io/devcontainers/features/nvidia-cuda:1": {
                    "installCudnn": True
                }
            },
            "postCreateCommand": "pip install pandas scikit-learn matplotlib seaborn",
            "forwardPorts": [8888, 6006]
        }
        
        params = CreateSandboxParams(
            language="python",
            devcontainer_config=json.dumps(devcontainer_config)
        )
        
        return self.client.create(params)
    
    def create_web_environment(self):
        """åˆ›å»º Web å¼€å‘ç¯å¢ƒ"""
        devcontainer_config = {
            "name": "Web Dev Sandbox",
            "image": "node:18-bullseye",
            "features": {
                "ghcr.io/devcontainers/features/docker-in-docker:2": {}
            },
            "postCreateCommand": "npm install -g @vue/cli create-react-app",
            "forwardPorts": [3000, 8080, 5173]
        }
        
        params = CreateSandboxParams(
            language="javascript",
            devcontainer_config=json.dumps(devcontainer_config)
        )
        
        return self.client.create(params)
    
    def deploy_model_service(self, sandbox, model_code):
        """éƒ¨ç½²æ¨¡å‹æœåŠ¡"""
        service_code = f"""
import flask
from flask import Flask, request, jsonify
import pickle
import numpy as np

app = Flask(__name__)

# æ¨¡å‹ä»£ç 
{model_code}

@app.route('/predict', methods=['POST'])
def predict():
    try:
        data = request.json
        # è¿™é‡Œæ·»åŠ é¢„æµ‹é€»è¾‘
        result = {{"prediction": "success", "data": data}}
        return jsonify(result)
    except Exception as e:
        return jsonify({{"error": str(e)}}), 500

@app.route('/health', methods=['GET'])
def health():
    return jsonify({{"status": "healthy"}})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True)
"""
        
        # åœ¨æ²™ç›’ä¸­æ‰§è¡ŒæœåŠ¡ä»£ç 
        response = sandbox.process.code_run(service_code)
        return response
    
    def manage_container_lifecycle(self, sandbox_id, action):
        """ç®¡ç†å®¹å™¨ç”Ÿå‘½å‘¨æœŸ"""
        actions = {
            'start': lambda: self.client.start(sandbox_id),
            'stop': lambda: self.client.stop(sandbox_id),
            'restart': lambda: self.client.restart(sandbox_id),
            'remove': lambda: self.client.remove(sandbox_id)
        }
        
        if action in actions:
            try:
                return actions[action]()
            except Exception as e:
                print(f"âŒ æ“ä½œ {action} å¤±è´¥: {e}")
                return None
        else:
            print(f"âŒ ä¸æ”¯æŒçš„æ“ä½œ: {action}")
            return None
    
    def monitor_resources(self, sandbox):
        """ç›‘æ§èµ„æºä½¿ç”¨æƒ…å†µ"""
        try:
            # è·å–å®¹å™¨ç»Ÿè®¡ä¿¡æ¯
            stats_code = """
import psutil
import json

stats = {
    'cpu_percent': psutil.cpu_percent(interval=1),
    'memory_info': dict(psutil.virtual_memory()._asdict()),
    'disk_usage': dict(psutil.disk_usage('/')._asdict()),
    'network_stats': dict(psutil.net_io_counters()._asdict())
}

print(json.dumps(stats, indent=2))
"""
            
            response = sandbox.process.code_run(stats_code)
            if response.exit_code == 0:
                return json.loads(response.result)
            else:
                return None
                
        except Exception as e:
            print(f"âŒ ç›‘æ§å¤±è´¥: {e}")
            return None

# ä½¿ç”¨ç¤ºä¾‹
def main():
    API_KEY = "your-api-key-here"
    scheduler = DockerScheduler(API_KEY)
    
    print("ğŸš€ åˆ›å»ºæœºå™¨å­¦ä¹ ç¯å¢ƒ...")
    ml_sandbox = scheduler.create_ml_environment()
    
    if ml_sandbox:
        print(f"âœ… ML ç¯å¢ƒåˆ›å»ºæˆåŠŸ: {ml_sandbox.id}")
        
        # ç›‘æ§èµ„æº
        print("ğŸ“Š ç›‘æ§èµ„æºä½¿ç”¨...")
        stats = scheduler.monitor_resources(ml_sandbox)
        if stats:
            print(f"CPU ä½¿ç”¨ç‡: {stats['cpu_percent']}%")
            print(f"å†…å­˜ä½¿ç”¨: {stats['memory_info']['percent']}%")
        
        # éƒ¨ç½²ç®€å•çš„æ¨¡å‹æœåŠ¡
        model_code = """
def simple_model(data):
    # ç®€å•çš„çº¿æ€§æ¨¡å‹ç¤ºä¾‹
    return sum(data) / len(data) if data else 0
"""
        
        print("ğŸ”„ éƒ¨ç½²æ¨¡å‹æœåŠ¡...")
        scheduler.deploy_model_service(ml_sandbox, model_code)
        
        # ç­‰å¾…ä¸€æ®µæ—¶é—´åæ¸…ç†
        time.sleep(10)
        print("ğŸ—‘ï¸ æ¸…ç†ç¯å¢ƒ...")
        scheduler.manage_container_lifecycle(ml_sandbox.id, 'remove')

if __name__ == "__main__":
    main()
```

### 5.3 æ‰¹é‡å®¹å™¨ç®¡ç†

```python
# batch_manager.py
from daytona_sdk import Daytona, DaytonaConfig, CreateSandboxParams
import concurrent.futures
import time

class BatchContainerManager:
    def __init__(self, api_key):
        self.config = DaytonaConfig(
            api_url="http://localhost:3000",
            api_key=api_key
        )
        self.client = Daytona(self.config)
    
    def create_multiple_sandboxes(self, configs):
        """å¹¶è¡Œåˆ›å»ºå¤šä¸ªæ²™ç›’"""
        def create_single(config):
            try:
                params = CreateSandboxParams(**config)
                sandbox = self.client.create(params)
                return {"success": True, "sandbox": sandbox, "config": config}
            except Exception as e:
                return {"success": False, "error": str(e), "config": config}
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
            futures = [executor.submit(create_single, config) for config in configs]
            results = [future.result() for future in concurrent.futures.as_completed(futures)]
        
        return results
    
    def execute_parallel_tasks(self, sandboxes, tasks):
        """åœ¨å¤šä¸ªæ²™ç›’ä¸­å¹¶è¡Œæ‰§è¡Œä»»åŠ¡"""
        def execute_task(sandbox_task):
            sandbox, task = sandbox_task
            try:
                response = sandbox.process.code_run(task['code'])
                return {
                    "sandbox_id": sandbox.id,
                    "task_name": task['name'],
                    "success": response.exit_code == 0,
                    "result": response.result
                }
            except Exception as e:
                return {
                    "sandbox_id": sandbox.id,
                    "task_name": task['name'],
                    "success": False,
                    "error": str(e)
                }
        
        sandbox_tasks = [(sandbox, task) for sandbox in sandboxes for task in tasks]
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=len(sandboxes)) as executor:
            futures = [executor.submit(execute_task, st) for st in sandbox_tasks]
            results = [future.result() for future in concurrent.futures.as_completed(futures)]
        
        return results
    
    def cleanup_all(self, sandboxes):
        """æ¸…ç†æ‰€æœ‰æ²™ç›’"""
        def cleanup_single(sandbox):
            try:
                self.client.remove(sandbox)
                return {"success": True, "sandbox_id": sandbox.id}
            except Exception as e:
                return {"success": False, "sandbox_id": sandbox.id, "error": str(e)}
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
            futures = [executor.submit(cleanup_single, sandbox) for sandbox in sandboxes]
            results = [future.result() for future in concurrent.futures.as_completed(futures)]
        
        return results

# ä½¿ç”¨ç¤ºä¾‹
def batch_processing_example():
    API_KEY = "your-api-key-here"
    manager = BatchContainerManager(API_KEY)
    
    # å®šä¹‰å¤šä¸ªç¯å¢ƒé…ç½®
    configs = [
        {"language": "python", "image": "python:3.9"},
        {"language": "python", "image": "python:3.10"},
        {"language": "python", "image": "python:3.11"},
    ]
    
    print("ğŸš€ æ‰¹é‡åˆ›å»ºæ²™ç›’ç¯å¢ƒ...")
    results = manager.create_multiple_sandboxes(configs)
    
    successful_sandboxes = [r["sandbox"] for r in results if r["success"]]
    print(f"âœ… æˆåŠŸåˆ›å»º {len(successful_sandboxes)} ä¸ªæ²™ç›’")
    
    # å®šä¹‰è¦æ‰§è¡Œçš„ä»»åŠ¡
    tasks = [
        {
            "name": "python_version",
            "code": "import sys; print(f'Python {sys.version}')"
        },
        {
            "name": "basic_computation",
            "code": "result = sum(range(1000)); print(f'Sum: {result}')"
        }
    ]
    
    if successful_sandboxes:
        print("âš¡ æ‰§è¡Œå¹¶è¡Œä»»åŠ¡...")
        task_results = manager.execute_parallel_tasks(successful_sandboxes, tasks)
        
        for result in task_results:
            if result["success"]:
                print(f"âœ… {result['task_name']} @ {result['sandbox_id']}: {result['result']}")
            else:
                print(f"âŒ {result['task_name']} @ {result['sandbox_id']}: {result.get('error', 'Unknown error')}")
        
        # æ¸…ç†æ‰€æœ‰æ²™ç›’
        print("ğŸ—‘ï¸ æ¸…ç†æ‰€æœ‰æ²™ç›’...")
        cleanup_results = manager.cleanup_all(successful_sandboxes)
        successful_cleanups = sum(1 for r in cleanup_results if r["success"])
        print(f"âœ… æˆåŠŸæ¸…ç† {successful_cleanups} ä¸ªæ²™ç›’")

if __name__ == "__main__":
    batch_processing_example()
```

## 6. é«˜çº§ç”¨æ³•ä¸æœ€ä½³å®è·µ

### 6.1 ç¯å¢ƒæ¨¡æ¿ç®¡ç†

```python
# template_manager.py
from dataclasses import dataclass
from typing import Dict, List, Optional
import json

@dataclass
class EnvironmentTemplate:
    name: str
    description: str
    image: str
    features: Dict
    extensions: List[str]
    settings: Dict
    post_create_commands: List[str]
    forward_ports: List[int]

class TemplateManager:
    def __init__(self):
        self.templates = {}
        self._load_default_templates()
    
    def _load_default_templates(self):
        """åŠ è½½é»˜è®¤æ¨¡æ¿"""
        # æ•°æ®ç§‘å­¦æ¨¡æ¿
        self.templates["data-science"] = EnvironmentTemplate(
            name="æ•°æ®ç§‘å­¦ç¯å¢ƒ",
            description="åŒ…å« Jupyterã€pandasã€scikit-learn ç­‰å·¥å…·",
            image="jupyter/datascience-notebook:latest",
            features={
                "ghcr.io/devcontainers/features/nvidia-cuda:1": {
                    "installCudnn": True
                }
            },
            extensions=[
                "ms-python.python",
                "ms-toolsai.jupyter",
                "ms-python.vscode-pylance"
            ],
            settings={
                "python.defaultInterpreterPath": "/opt/conda/bin/python"
            },
            post_create_commands=[
                "pip install mlflow wandb",
                "conda install -c conda-forge dask"
            ],
            forward_ports=[8888, 4040]
        )
        
        # Web å¼€å‘æ¨¡æ¿
        self.templates["web-dev"] = EnvironmentTemplate(
            name="Web å¼€å‘ç¯å¢ƒ",
            description="Node.js + React/Vue å¼€å‘ç¯å¢ƒ",
            image="node:18-bullseye",
            features={
                "ghcr.io/devcontainers/features/docker-in-docker:2": {}
            },
            extensions=[
                "ms-vscode.vscode-typescript-next",
                "bradlc.vscode-tailwindcss",
                "esbenp.prettier-vscode"
            ],
            settings={
                "editor.formatOnSave": True,
                "editor.defaultFormatter": "esbenp.prettier-vscode"
            },
            post_create_commands=[
                "npm install -g @vue/cli create-react-app",
                "npm install -g typescript ts-node"
            ],
            forward_ports=[3000, 8080, 5173]
        )
    
    def get_template(self, name: str) -> Optional[EnvironmentTemplate]:
        """è·å–æ¨¡æ¿"""
        return self.templates.get(name)
    
    def create_devcontainer_config(self, template_name: str) -> Dict:
        """åŸºäºæ¨¡æ¿åˆ›å»º devcontainer é…ç½®"""
        template = self.get_template(template_name)
        if not template:
            raise ValueError(f"æ¨¡æ¿ '{template_name}' ä¸å­˜åœ¨")
        
        config = {
            "name": template.name,
            "image": template.image,
            "features": template.features,
            "customizations": {
                "vscode": {
                    "extensions": template.extensions,
                    "settings": template.settings
                }
            },
            "postCreateCommand": " && ".join(template.post_create_commands),
            "forwardPorts": template.forward_ports
        }
        
        return config
    
    def add_custom_template(self, template: EnvironmentTemplate):
        """æ·»åŠ è‡ªå®šä¹‰æ¨¡æ¿"""
        self.templates[template.name] = template
    
    def list_templates(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡æ¿"""
        return list(self.templates.keys())

# ä½¿ç”¨ç¤ºä¾‹
template_manager = TemplateManager()
print("å¯ç”¨æ¨¡æ¿:", template_manager.list_templates())

# åˆ›å»ºæ•°æ®ç§‘å­¦ç¯å¢ƒé…ç½®
ds_config = template_manager.create_devcontainer_config("data-science")
print("æ•°æ®ç§‘å­¦ç¯å¢ƒé…ç½®:")
print(json.dumps(ds_config, indent=2, ensure_ascii=False))
```

### 6.2 è‡ªåŠ¨åŒ–å·¥ä½œæµ

```python
# workflow_automation.py
from daytona_sdk import Daytona, DaytonaConfig
import yaml
import time
from typing import List, Dict, Any

class WorkflowAutomation:
    def __init__(self, api_key: str):
        self.config = DaytonaConfig(api_key=api_key)
        self.client = Daytona(self.config)
        self.workflows = {}
    
    def load_workflow(self, workflow_file: str):
        """ä» YAML æ–‡ä»¶åŠ è½½å·¥ä½œæµå®šä¹‰"""
        with open(workflow_file, 'r', encoding='utf-8') as f:
            workflow = yaml.safe_load(f)
        
        workflow_name = workflow.get('name')
        self.workflows[workflow_name] = workflow
        return workflow_name
    
    def execute_workflow(self, workflow_name: str, variables: Dict[str, Any] = None):
        """æ‰§è¡Œå·¥ä½œæµ"""
        if workflow_name not in self.workflows:
            raise ValueError(f"å·¥ä½œæµ '{workflow_name}' ä¸å­˜åœ¨")
        
        workflow = self.workflows[workflow_name]
        variables = variables or {}
        
        print(f"ğŸš€ å¼€å§‹æ‰§è¡Œå·¥ä½œæµ: {workflow_name}")
        
        # åˆ›å»ºç¯å¢ƒ
        sandbox = self._create_environment(workflow.get('environment', {}))
        if not sandbox:
            return None
        
        try:
            # æ‰§è¡Œæ­¥éª¤
            results = []
            for step in workflow.get('steps', []):
                result = self._execute_step(sandbox, step, variables)
                results.append(result)
                
                if not result.get('success', False):
                    print(f"âŒ æ­¥éª¤å¤±è´¥: {step.get('name', 'Unknown')}")
                    break
            
            # æ”¶é›†è¾“å‡º
            outputs = self._collect_outputs(sandbox, workflow.get('outputs', []))
            
            return {
                'success': all(r.get('success', False) for r in results),
                'results': results,
                'outputs': outputs,
                'sandbox_id': sandbox.id
            }
            
        finally:
            # æ¸…ç†ç¯å¢ƒï¼ˆå¦‚æœé…ç½®äº†è‡ªåŠ¨æ¸…ç†ï¼‰
            if workflow.get('cleanup', True):
                self.client.remove(sandbox)
    
    def _create_environment(self, env_config: Dict) -> Any:
        """åˆ›å»ºç¯å¢ƒ"""
        # è¿™é‡Œå¯ä»¥æ ¹æ® env_config åˆ›å»ºç›¸åº”çš„æ²™ç›’
        # ç¤ºä¾‹å®ç°
        return self.client.create(env_config)
    
    def _execute_step(self, sandbox: Any, step: Dict, variables: Dict) -> Dict:
        """æ‰§è¡Œå•ä¸ªæ­¥éª¤"""
        step_name = step.get('name', 'Unknown Step')
        print(f"âš¡ æ‰§è¡Œæ­¥éª¤: {step_name}")
        
        # æ›¿æ¢å˜é‡
        command = step.get('command', '')
        for var, value in variables.items():
            command = command.replace(f"${{{var}}}", str(value))
        
        try:
            response = sandbox.process.code_run(command)
            success = response.exit_code == 0
            
            if success:
                print(f"âœ… æ­¥éª¤æˆåŠŸ: {step_name}")
            else:
                print(f"âŒ æ­¥éª¤å¤±è´¥: {step_name}")
                print(f"é”™è¯¯: {response.result}")
            
            return {
                'step_name': step_name,
                'success': success,
                'output': response.result,
                'exit_code': response.exit_code
            }
            
        except Exception as e:
            print(f"âŒ æ­¥éª¤å¼‚å¸¸: {step_name} - {e}")
            return {
                'step_name': step_name,
                'success': False,
                'error': str(e)
            }
    
    def _collect_outputs(self, sandbox: Any, output_configs: List[Dict]) -> Dict:
        """æ”¶é›†è¾“å‡º"""
        outputs = {}
        
        for output_config in output_configs:
            name = output_config.get('name')
            command = output_config.get('command')
            
            try:
                response = sandbox.process.code_run(command)
                if response.exit_code == 0:
                    outputs[name] = response.result
                else:
                    outputs[name] = f"Error: {response.result}"
            except Exception as e:
                outputs[name] = f"Exception: {e}"
        
        return outputs

# å·¥ä½œæµé…ç½®ç¤ºä¾‹ (workflow.yaml)
workflow_yaml_example = """
name: "ml_model_training"
description: "æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒå·¥ä½œæµ"

environment:
  language: "python"
  image: "tensorflow/tensorflow:2.15.0-gpu"

variables:
  dataset_url: "https://example.com/dataset.csv"
  model_name: "my_model"
  epochs: 10

steps:
  - name: "å®‰è£…ä¾èµ–"
    command: |
      pip install pandas scikit-learn matplotlib

  - name: "ä¸‹è½½æ•°æ®"
    command: |
      wget ${dataset_url} -O dataset.csv

  - name: "è®­ç»ƒæ¨¡å‹"
    command: |
      python -c "
      import pandas as pd
      from sklearn.model_selection import train_test_split
      from sklearn.linear_model import LogisticRegression
      import pickle
      
      # è¯»å–æ•°æ®ï¼ˆç¤ºä¾‹ï¼‰
      data = pd.read_csv('dataset.csv')
      # è¿™é‡Œæ·»åŠ å®é™…çš„è®­ç»ƒé€»è¾‘
      
      # ä¿å­˜æ¨¡å‹
      model = LogisticRegression()
      with open('${model_name}.pkl', 'wb') as f:
          pickle.dump(model, f)
      
      print('æ¨¡å‹è®­ç»ƒå®Œæˆ')
      "

  - name: "éªŒè¯æ¨¡å‹"
    command: |
      python -c "
      import pickle
      
      with open('${model_name}.pkl', 'rb') as f:
          model = pickle.load(f)
      
      print('æ¨¡å‹éªŒè¯é€šè¿‡')
      "

outputs:
  - name: "model_file"
    command: "ls -la ${model_name}.pkl"
  
  - name: "training_log"
    command: "cat training.log"

cleanup: true
"""

# ä¿å­˜ç¤ºä¾‹å·¥ä½œæµ
with open('ml_workflow.yaml', 'w', encoding='utf-8') as f:
    f.write(workflow_yaml_example)

# ä½¿ç”¨ç¤ºä¾‹
def run_workflow_example():
    API_KEY = "your-api-key-here"
    automation = WorkflowAutomation(API_KEY)
    
    # åŠ è½½å·¥ä½œæµ
    workflow_name = automation.load_workflow('ml_workflow.yaml')
    
    # æ‰§è¡Œå·¥ä½œæµ
    variables = {
        'dataset_url': 'https://raw.githubusercontent.com/datasets/iris/master/data/iris.csv',
        'model_name': 'iris_model',
        'epochs': 5
    }
    
    result = automation.execute_workflow(workflow_name, variables)
    
    if result and result['success']:
        print("ğŸ‰ å·¥ä½œæµæ‰§è¡ŒæˆåŠŸ!")
        print("è¾“å‡º:")
        for name, output in result['outputs'].items():
            print(f"  {name}: {output}")
    else:
        print("âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥")

if __name__ == "__main__":
    run_workflow_example()
```

## 7. å¸¸è§é—®é¢˜è§£å†³

### 7.1 è¿æ¥é—®é¢˜

```python
# troubleshooting.py
import requests
import time
from daytona_sdk import DaytonaConfig

def check_daytona_server(url="http://localhost:3000"):
    """æ£€æŸ¥ Daytona æœåŠ¡å™¨çŠ¶æ€"""
    try:
        response = requests.get(f"{url}/health", timeout=5)
        if response.status_code == 200:
            print("âœ… Daytona æœåŠ¡å™¨è¿è¡Œæ­£å¸¸")
            return True
        else:
            print(f"âš ï¸ Daytona æœåŠ¡å™¨å“åº”å¼‚å¸¸: {response.status_code}")
            return False
    except requests.exceptions.RequestException as e:
        print(f"âŒ æ— æ³•è¿æ¥åˆ° Daytona æœåŠ¡å™¨: {e}")
        return False

def validate_api_key(api_key, server_url="http://localhost:3000"):
    """éªŒè¯ API Key"""
    try:
        headers = {"Authorization": f"Bearer {api_key}"}
        response = requests.get(f"{server_url}/api/user", headers=headers, timeout=5)
        
        if response.status_code == 200:
            print("âœ… API Key æœ‰æ•ˆ")
            return True
        elif response.status_code == 401:
            print("âŒ API Key æ— æ•ˆæˆ–å·²è¿‡æœŸ")
            return False
        else:
            print(f"âš ï¸ éªŒè¯ API Key æ—¶å‡ºç°å¼‚å¸¸: {response.status_code}")
            return False
    except requests.exceptions.RequestException as e:
        print(f"âŒ éªŒè¯ API Key æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return False

def diagnose_docker_issues():
    """è¯Šæ–­ Docker é—®é¢˜"""
    import subprocess
    
    try:
        # æ£€æŸ¥ Docker æ˜¯å¦è¿è¡Œ
        result = subprocess.run(['docker', '--version'], 
                              capture_output=True, text=True, timeout=5)
        if result.returncode == 0:
            print("âœ… Docker å·²å®‰è£…")
            print(f"ç‰ˆæœ¬: {result.stdout.strip()}")
        else:
            print("âŒ Docker æœªæ­£ç¡®å®‰è£…")
            return False
        
        # æ£€æŸ¥ Docker æœåŠ¡çŠ¶æ€
        result = subprocess.run(['docker', 'info'], 
                              capture_output=True, text=True, timeout=5)
        if result.returncode == 0:
            print("âœ… Docker æœåŠ¡è¿è¡Œæ­£å¸¸")
        else:
            print("âŒ Docker æœåŠ¡æœªè¿è¡Œ")
            print("è¯·å¯åŠ¨ Docker æœåŠ¡: sudo systemctl start docker")
            return False
        
        # æ£€æŸ¥ç”¨æˆ·æƒé™
        result = subprocess.run(['docker', 'ps'], 
                              capture_output=True, text=True, timeout=5)
        if result.returncode == 0:
            print("âœ… Docker æƒé™æ­£å¸¸")
        else:
            print("âš ï¸ Docker æƒé™é—®é¢˜")
            print("è¯·å°†ç”¨æˆ·æ·»åŠ åˆ° docker ç»„: sudo usermod -aG docker $USER")
            print("ç„¶åé‡æ–°ç™»å½•")
            
        return True
        
    except subprocess.TimeoutExpired:
        print("âŒ Docker å‘½ä»¤æ‰§è¡Œè¶…æ—¶")
        return False
    except FileNotFoundError:
        print("âŒ Docker æœªå®‰è£…")
        return False

def system_diagnostics():
    """ç³»ç»Ÿè¯Šæ–­"""
    print("ğŸ” å¼€å§‹ç³»ç»Ÿè¯Šæ–­...")
    print("=" * 50)
    
    # æ£€æŸ¥ Daytona æœåŠ¡å™¨
    print("1. æ£€æŸ¥ Daytona æœåŠ¡å™¨çŠ¶æ€:")
    server_ok = check_daytona_server()
    print()
    
    # æ£€æŸ¥ Docker
    print("2. æ£€æŸ¥ Docker çŠ¶æ€:")
    docker_ok = diagnose_docker_issues()
    print()
    
    # æ£€æŸ¥ Python ç¯å¢ƒ
    print("3. æ£€æŸ¥ Python ç¯å¢ƒ:")
    try:
        import daytona_sdk
        print("âœ… Daytona SDK å·²å®‰è£…")
        print(f"ç‰ˆæœ¬: {daytona_sdk.__version__}")
    except ImportError:
        print("âŒ Daytona SDK æœªå®‰è£…")
        print("è¯·è¿è¡Œ: pip install daytona-sdk")
    except AttributeError:
        print("âœ… Daytona SDK å·²å®‰è£…ï¼ˆç‰ˆæœ¬ä¿¡æ¯ä¸å¯ç”¨ï¼‰")
    print()
    
    # æ€»ç»“
    print("è¯Šæ–­ç»“æœ:")
    if server_ok and docker_ok:
        print("ğŸ‰ ç³»ç»Ÿé…ç½®æ­£å¸¸ï¼Œå¯ä»¥å¼€å§‹ä½¿ç”¨ Daytona!")
    else:
        print("âš ï¸ å‘ç°é—®é¢˜ï¼Œè¯·æ ¹æ®ä¸Šè¿°æç¤ºè¿›è¡Œä¿®å¤")

if __name__ == "__main__":
    system_diagnostics()
```

### 7.2 æ€§èƒ½ä¼˜åŒ–

```python
# performance_optimization.py
import psutil
import time
from daytona_sdk import Daytona, DaytonaConfig

class PerformanceOptimizer:
    def __init__(self, api_key):
        self.config = DaytonaConfig(api_key=api_key)
        self.client = Daytona(self.config)
    
    def optimize_sandbox_resources(self, sandbox, cpu_limit=None, memory_limit=None):
        """ä¼˜åŒ–æ²™ç›’èµ„æºé…ç½®"""
        optimization_script = f"""
import os
import subprocess

# è®¾ç½® CPU é™åˆ¶
if {cpu_limit is not None}:
    # è¿™é‡Œå¯ä»¥æ·»åŠ  CPU é™åˆ¶é€»è¾‘
    print(f"è®¾ç½® CPU é™åˆ¶: {cpu_limit}")

# è®¾ç½®å†…å­˜é™åˆ¶  
if {memory_limit is not None}:
    # è¿™é‡Œå¯ä»¥æ·»åŠ å†…å­˜é™åˆ¶é€»è¾‘
    print(f"è®¾ç½®å†…å­˜é™åˆ¶: {memory_limit}")

# æ¸…ç†ä¸å¿…è¦çš„è¿›ç¨‹
subprocess.run(['apt-get', 'clean'], check=False)
subprocess.run(['apt-get', 'autoremove', '-y'], check=False)

print("èµ„æºä¼˜åŒ–å®Œæˆ")
"""
        
        return sandbox.process.code_run(optimization_script)
    
    def monitor_performance(self, sandbox, duration=60):
        """ç›‘æ§æ€§èƒ½æŒ‡æ ‡"""
        monitoring_script = f"""
import psutil
import time
import json

def collect_metrics():
    return {{
        'timestamp': time.time(),
        'cpu_percent': psutil.cpu_percent(interval=1),
        'memory': dict(psutil.virtual_memory()._asdict()),
        'disk': dict(psutil.disk_usage('/')._asdict()),
        'network': dict(psutil.net_io_counters()._asdict()),
        'processes': len(psutil.pids())
    }}

metrics = []
start_time = time.time()

while time.time() - start_time < {duration}:
    metrics.append(collect_metrics())
    time.sleep(5)

# è®¡ç®—å¹³å‡å€¼
if metrics:
    avg_cpu = sum(m['cpu_percent'] for m in metrics) / len(metrics)
    avg_memory = sum(m['memory']['percent'] for m in metrics) / len(metrics)
    
    print(f"å¹³å‡ CPU ä½¿ç”¨ç‡: {{avg_cpu:.2f}}%")
    print(f"å¹³å‡å†…å­˜ä½¿ç”¨ç‡: {{avg_memory:.2f}}%")
    print(f"é‡‡é›†äº† {{len(metrics)}} ä¸ªæ•°æ®ç‚¹")
else:
    print("æœªé‡‡é›†åˆ°æ€§èƒ½æ•°æ®")
"""
        
        return sandbox.process.code_run(monitoring_script)
    
    def suggest_optimizations(self):
        """å»ºè®®ä¼˜åŒ–æªæ–½"""
        print("ğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®:")
        print("1. å®šæœŸæ¸…ç†æœªä½¿ç”¨çš„æ²™ç›’")
        print("2. ä½¿ç”¨èµ„æºé™åˆ¶é¿å…å•ä¸ªæ²™ç›’å ç”¨è¿‡å¤šèµ„æº") 
        print("3. ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ")
        print("4. ä½¿ç”¨ SSD å­˜å‚¨æé«˜ I/O æ€§èƒ½")
        print("5. å¢åŠ å†…å­˜å¯ä»¥æé«˜å®¹å™¨å¯åŠ¨é€Ÿåº¦")

# ä½¿ç”¨ç¤ºä¾‹
def optimize_performance():
    API_KEY = "your-api-key-here"
    optimizer = PerformanceOptimizer(API_KEY)
    
    # æ˜¾ç¤ºä¼˜åŒ–å»ºè®®
    optimizer.suggest_optimizations()

if __name__ == "__main__":
    optimize_performance()
```

## æ€»ç»“

é€šè¿‡æœ¬æ•™ç¨‹ï¼Œæ‚¨å·²ç»å­¦ä¼šäº†ï¼š

1. **Daytona çš„åŸºæœ¬æ¦‚å¿µå’Œå®‰è£…**
2. **Python SDK çš„ä½¿ç”¨æ–¹æ³•**
3. **Docker å®¹å™¨çš„è°ƒåº¦å’Œç®¡ç†**
4. **é«˜çº§åŠŸèƒ½å¦‚æ‰¹é‡ç®¡ç†ã€æ¨¡æ¿ç³»ç»Ÿã€å·¥ä½œæµè‡ªåŠ¨åŒ–**
5. **æ•…éšœæ’é™¤å’Œæ€§èƒ½ä¼˜åŒ–**

### ä¸‹ä¸€æ­¥å»ºè®®

1. **æ¢ç´¢æ›´å¤šæ¨¡æ¿**ï¼šåˆ›å»ºé€‚åˆæ‚¨é¡¹ç›®çš„è‡ªå®šä¹‰ç¯å¢ƒæ¨¡æ¿
2. **é›†æˆ CI/CD**ï¼šå°† Daytona é›†æˆåˆ°æ‚¨çš„æŒç»­é›†æˆæµç¨‹ä¸­
3. **å›¢é˜Ÿåä½œ**ï¼šè®¾ç½®å›¢é˜Ÿå…±äº«çš„å¼€å‘ç¯å¢ƒ
4. **ç›‘æ§å’Œæ—¥å¿—**ï¼šå»ºç«‹å®Œå–„çš„ç›‘æ§å’Œæ—¥å¿—ç³»ç»Ÿ

### æœ‰ç”¨çš„èµ„æº

- [Daytona å®˜æ–¹æ–‡æ¡£](https://docs.daytona.io)
- [Dev Container è§„èŒƒ](https://containers.dev)
- [Docker æœ€ä½³å®è·µ](https://docs.docker.com/develop/dev-best-practices/)

ç¥æ‚¨ä½¿ç”¨ Daytona æ„‰å¿«ï¼ğŸš€